# üö¢ Titanic Survival Prediction  
### Kaggle Competition ‚Äì Machine Learning from Disaster

Este projeto tem como objetivo prever a sobreviv√™ncia dos passageiros do Titanic utilizando t√©cnicas de Machine Learning. O desenvolvimento foi estruturado em etapas, permitindo avaliar como diferentes estrat√©gias de tratamento e modelagem impactam o desempenho final.

---

## üéØ Objetivo

Construir modelos preditivos capazes de estimar a probabilidade de sobreviv√™ncia com base em vari√°veis demogr√°ficas e socioecon√¥micas, analisando a evolu√ß√£o dos resultados ao longo das melhorias aplicadas.

---

## üî¨ Desenvolvimento do Projeto

O projeto foi dividido em **cinco etapas progressivas**, cada uma focada em melhorias espec√≠ficas no pipeline.

---

## üß± Etapa 1 ‚Äì Modelo Inicial

Nesta etapa foi aplicado apenas o tratamento b√°sico dos dados, com o objetivo de estabelecer um **baseline** para compara√ß√£o.

### ‚úî O que foi feito:

- An√°lise explorat√≥ria utilizando **ydata-profiling**
- Remo√ß√£o de colunas com alta cardinalidade
- Tratamento de valores ausentes:
  - M√©dia para vari√°veis num√©ricas
  - Moda para vari√°veis categ√≥ricas
- Exclus√£o de colunas textuais
- Treinamento dos modelos:
  - **√Årvore de Decis√£o**
  - **K-Nearest Neighbors (KNN)**
  - **Regress√£o Log√≠stica**
- Avalia√ß√£o com:
  - **Acur√°cia**
  - **Matriz de confus√£o**

**Score p√∫blico no Kaggle:** `0.66746`

---

## üß© Etapa 2 ‚Äì Tratamento das Vari√°veis Categ√≥ricas

O foco foi incorporar corretamente as vari√°veis categ√≥ricas ao modelo.

### ‚úî Melhorias implementadas:

- Transforma√ß√µes personalizadas com `lambda`
- Codifica√ß√£o utilizando **OneHotEncoder**
- Manuten√ß√£o dos mesmos algoritmos para compara√ß√£o controlada

**Score p√∫blico no Kaggle:** `0.76555`

üìà Houve ganho significativo apenas com o tratamento adequado das vari√°veis categ√≥ricas.

---

## üß† Etapa 3 ‚Äì Engenharia de Atributos

Nesta fase, o objetivo foi aprofundar a compreens√£o dos dados e extrair informa√ß√µes adicionais relevantes.

### ‚úî Ajustes realizados:

- Padroniza√ß√£o das vari√°veis `Age` e `Fare`
- Cria√ß√£o de novas features:
  - `FamilySize = SibSp + Parch + 1`
  - `IsAlone` (indicador bin√°rio)
- An√°lise de correla√ß√£o para sele√ß√£o de vari√°veis mais relevantes

Os mesmos modelos foram mantidos para garantir consist√™ncia na compara√ß√£o.

**Score p√∫blico no Kaggle:** `0.77033`

---

## ü§ñ Etapa 4 ‚Äì Modelos Mais Complexos

Foram mantidas todas as vari√°veis e testados modelos com maior capacidade de ajuste.

### ‚úî Algoritmos avaliados:

- **Regress√£o Log√≠stica**
- **Random Forest**
- **MLPClassifier (Rede Neural)**

O **MLPClassifier** apresentou a maior acur√°cia na valida√ß√£o, por√©m teve pior desempenho na submiss√£o final.

**Score p√∫blico no Kaggle:** `0.69856`

‚ö† Isso indica prov√°vel **overfitting**, com perda de capacidade de generaliza√ß√£o.

---

## ‚öôÔ∏è Etapa 5 ‚Äì Otimiza√ß√£o com GridSearchCV

Aplica√ß√£o do **GridSearchCV** para encontrar os melhores hiperpar√¢metros dos modelos testados na etapa anterior.

Ap√≥s a otimiza√ß√£o:

- O modelo com melhor desempenho foi o **Random Forest**
- Houve melhora consistente tanto na valida√ß√£o quanto na submiss√£o

**Score p√∫blico no Kaggle:** `0.78229`

---

## üìä Evolu√ß√£o dos Resultados

| Etapa | Estrat√©gia | Score P√∫blico |
|-------|------------|--------------|
| 1 | Modelo b√°sico | 0.66746 |
| 2 | Tratamento categ√≥rico | 0.76555 |
| 3 | Engenharia de atributos | 0.77033 |
| 4 | Modelos complexos | 0.69856 |
| 5 | GridSearchCV | **0.78229** |

---

## üß† Principais Aprendizados

- O tratamento adequado das vari√°veis categ√≥ricas teve grande impacto no desempenho.
- Engenharia de atributos pode ser mais relevante que aumentar a complexidade do modelo.
- Modelos mais complexos n√£o garantem melhor generaliza√ß√£o.
- Ajuste de hiperpar√¢metros √© essencial para extrair o melhor desempenho dos modelos.
- Experimenta√ß√£o estruturada facilita a an√°lise e a evolu√ß√£o do pipeline.

---

## üõ† Tecnologias Utilizadas

- Python
- Pandas
- NumPy
- Scikit-Learn
- Matplotlib
- Seaborn
- ydata-profiling
